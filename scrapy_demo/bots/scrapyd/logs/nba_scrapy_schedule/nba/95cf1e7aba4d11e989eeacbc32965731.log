2019-08-09 02:30:06 [scrapy.utils.log] INFO: Scrapy 1.7.3 started (bot: nbatest)
2019-08-09 02:30:06 [scrapy.utils.log] INFO: Versions: lxml 4.4.0.0, libxml2 2.9.9, cssselect 1.0.3, parsel 1.5.1, w3lib 1.20.0, Twisted 19.7.0, Python 3.7.4 (v3.7.4:e09359112e, Jul  8 2019, 14:54:52) - [Clang 6.0 (clang-600.0.57)], pyOpenSSL 19.0.0 (OpenSSL 1.1.1c  28 May 2019), cryptography 2.7, Platform Darwin-18.5.0-x86_64-i386-64bit
2019-08-09 02:30:06 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'nbatest', 'LOG_FILE': 'logs/nba_scrapy_schedule/nba/95cf1e7aba4d11e989eeacbc32965731.log', 'NEWSPIDER_MODULE': 'nbatest.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['nbatest.spiders']}
2019-08-09 02:30:06 [scrapy.extensions.telnet] INFO: Telnet Password: 7de7dc664a015249
2019-08-09 02:30:06 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2019-08-09 02:30:06 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-08-09 02:30:06 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-08-09 02:30:06 [scrapy.middleware] INFO: Enabled item pipelines:
['nbatest.pipelines.NbatestPipeline']
2019-08-09 02:30:06 [scrapy.core.engine] INFO: Spider opened
2019-08-09 02:30:06 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-08-09 02:30:06 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2019-08-09 02:30:06 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nba.udn.com/robots.txt> (referer: None)
2019-08-09 02:30:06 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nba.udn.com/nba/index?gr=www> (referer: None)
2019-08-09 02:30:06 [py.warnings] WARNING: /private/var/folders/qt/nmbjkvbj0cs8rvvy_2cfjb800000gn/T/nba_scrapy_schedule-1565291530-mqdedjtw.egg/nbatest/spiders/crawler.py:12: UserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system ("lxml"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.

The code that caused this warning is on line 12 of the file /private/var/folders/qt/nmbjkvbj0cs8rvvy_2cfjb800000gn/T/nba_scrapy_schedule-1565291530-mqdedjtw.egg/nbatest/spiders/crawler.py. To get rid of this warning, pass the additional argument 'features="lxml"' to the BeautifulSoup constructor.


2019-08-09 02:30:06 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nba.udn.com/nba/story/6780/3979150> (referer: https://nba.udn.com/nba/index?gr=www)
2019-08-09 02:30:07 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nba.udn.com/nba/story/6780/3979132> (referer: https://nba.udn.com/nba/index?gr=www)
2019-08-09 02:30:07 [py.warnings] WARNING: /private/var/folders/qt/nmbjkvbj0cs8rvvy_2cfjb800000gn/T/nba_scrapy_schedule-1565291530-mqdedjtw.egg/nbatest/spiders/crawler.py:20: UserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system ("lxml"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.

The code that caused this warning is on line 20 of the file /private/var/folders/qt/nmbjkvbj0cs8rvvy_2cfjb800000gn/T/nba_scrapy_schedule-1565291530-mqdedjtw.egg/nbatest/spiders/crawler.py. To get rid of this warning, pass the additional argument 'features="lxml"' to the BeautifulSoup constructor.


2019-08-09 02:30:07 [py.warnings] WARNING: /Users/oliver/Documents/self/python/virtualenv/scrapy_demo/lib/python3.7/site-packages/django/db/models/fields/__init__.py:1421: RuntimeWarning: DateTimeField NbaNews.post_datetime received a naive datetime (2019-08-09 10:16:00) while time zone support is active.
  RuntimeWarning)

2019-08-09 02:30:07 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nba.udn.com/nba/story/6780/3979150>
{'content': '<p>曾是備受期待的大學超新星，前洛杉磯<a href="/search/tag/湖人" '
            'rel="87867"><strong>湖人</strong></a>前鋒畢斯利（Michael '
            'Beasley）在上賽季被交易到同城的<a href="/search/tag/快艇" '
            'rel="87866"><strong>快艇</strong></a>並被買斷合約後，雖然一度回到中國CBA賽場討生活，不過目前仍在尋求重返NBA機會的他，卻在今天傳出因違反聯盟禁藥規定將被處以五場禁賽，似乎與NBA舞台漸行漸遠。</p><p></p><p>高中就名滿全美的畢斯利，大學就讀堪薩斯州大時期更是囊括了當時年度各大獎項，讓他在投入NBA選秀前獲得了模板是安東尼（Carmelo '
            'Anthony）的高度評價，最終也在2008年選秀會第二順位被熱火挑中，展開起起伏伏的NBA生涯。</p><p></p><p>雖然在菜鳥球季畢斯利就獲得入選年度新秀第一隊的肯定，不過相較於同梯的羅斯（Derrick '
            'Rose）在聯盟中大放異彩，畢斯利進入聯盟後的成長卻是相當有限，加上場外風波不斷，在個人前三個賽季打完後就失去先發位置，並成為浪人球員，至今已經披過七支球隊戰袍，甚至還三度前往CBA討生活。</p><p></p><p>上個賽季畢斯利獲得湖人青睞披上紫金戰袍，不過前半賽季他都因為要照顧生病母親而缺陣，季中更被湖人打包送往快艇，隨後遭到釋出並加盟CBA廣東宏遠，雖然最終廣東順利奪冠，但畢斯利卻在季後賽完全神隱。而目前仍在尋求NBA合約的畢斯利，卻在今天傳出因違反聯盟禁藥規定，將遭到禁賽五場的處分，假使有球隊在未來與他簽約，禁賽處分將在第一時間生效。</p><p></p><p>在與NBA舞台漸行漸遠的情況下，畢斯利也傳出將會考慮繼續前往CBA討生活，過去他曾效力過上海、山東以及今年加盟的廣東，並在2016年以單季平均得分31.9分13.2籃板3.8助攻拿下年度最佳洋將，而今年加入廣東期間更傳出他的薪資高達200萬美元。</p><p></p><div '
            'class="video-container"><iframe allowfullscreen="" '
            'class="lazyload" frameborder="0" height="315" '
            'src="https://video.udn.com/embed/news/980972?autoplay=1&amp;muted=1" '
            'width="100%"></iframe></div>',
 'image_url': 'https://pgw.udn.com.tw/gw/photo.php?u=https://uc.udn.com.tw/photo/2019/08/09/1/6669599.jpg&x=0&y=0&sw=0&sh=0&sl=W&fw=1050&exp=3600',
 'post_datetime': '2019-08-09 10:16',
 'title': '違反規定用藥處禁賽 畢斯利恐失NBA舞台',
 'uid': '6780/3979150'}
2019-08-09 02:30:07 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nba.udn.com/nba/story/6780/3979168> (referer: https://nba.udn.com/nba/index?gr=www)
2019-08-09 02:30:07 [py.warnings] WARNING: /Users/oliver/Documents/self/python/virtualenv/scrapy_demo/lib/python3.7/site-packages/django/db/models/fields/__init__.py:1421: RuntimeWarning: DateTimeField NbaNews.post_datetime received a naive datetime (2019-08-09 09:40:00) while time zone support is active.
  RuntimeWarning)

2019-08-09 02:30:07 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nba.udn.com/nba/story/6780/3979132>
{'content': '<p>中國《騰訊體育》報導指出，退役馬刺傳奇球星<a href="/search/tag/帕克" '
            'rel="87888"><strong>帕克</strong></a>（Tony Parker）與<a '
            'href="/search/tag/吉諾布里" rel="87887"><strong>吉諾布里</strong></a>（<a '
            'href="/search/tag/Manu Ginobili" rel="87392"><strong>Manu '
            'Ginobili</strong></a>）將於9月21號現身於上海舉辦的超級企鵝聯盟紅藍大戰賽場。</p><p></p><p>超級企鵝聯盟紅藍大戰歷屆都會邀請NBA退役球員共襄盛舉，過去就有像是麥葛雷迪（Tracy '
            'McGrady）、畢拉普斯（Chauncey Billups）、艾倫（Ray Allen）、<a '
            'href="/search/tag/皮爾斯" rel="87903"><strong>皮爾斯</strong></a>（<a '
            'href="/search/tag/Paul Pierce" rel="116743"><strong>Paul '
            'Pierce</strong></a>）與波許（Chris '
            'Bosh）參與。</p><p></p><p>吉諾布里與帕克分別是在去年與今年相繼宣佈高掛球鞋退休，而本次紅藍大戰名人陣容中也包含來自台灣的藝人蕭敬騰、炎亞綸與顏行書。</p><p></p><div '
            'class="video-container"><iframe allowfullscreen="" '
            'class="lazyload" frameborder="0" height="315" '
            'src="https://video.udn.com/embed/news/1046176?autoplay=1&amp;muted=1" '
            'width="100%"></iframe></div>',
 'image_url': 'https://pgw.udn.com.tw/gw/photo.php?u=https://uc.udn.com.tw/photo/2019/08/09/99/6669516.jpg&x=0&y=0&sw=0&sh=0&sl=W&fw=1050&exp=3600',
 'post_datetime': '2019-08-09 09:40',
 'title': '中國表演賽公佈陣容 吉諾布里、帕克赫然在列',
 'uid': '6780/3979132'}
2019-08-09 02:30:07 [py.warnings] WARNING: /Users/oliver/Documents/self/python/virtualenv/scrapy_demo/lib/python3.7/site-packages/django/db/models/fields/__init__.py:1421: RuntimeWarning: DateTimeField NbaNews.post_datetime received a naive datetime (2019-08-09 10:08:00) while time zone support is active.
  RuntimeWarning)

2019-08-09 02:30:07 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nba.udn.com/nba/story/6780/3979168>
{'content': '<p><a href="/search/tag/詹姆斯" '
            'rel="87904"><strong>詹姆斯</strong></a>（<a href="/search/tag/LeBron '
            'James" rel="87697"><strong>LeBron '
            'James</strong></a>）場下事業經營的精準投資目光常為人津津樂道，像是入股英超勁旅利物浦或者過去成為耳機廠商Beats股東都替他帶回大量獲利，如今他所投資的美國連鎖比薩店Blaze '
            'Pizza更是後勢看漲。</p><p></p><p>《雅虎財經》報導，由1家消費者市調公司所統計最新報告指出，美國連鎖比薩店的消費者滿意度排名中，Blaze '
            'Pizza的69％領先了其他競爭者，甩開了像48％的達美樂與47％的必勝客，還有找來NBA明星歐尼爾（Shaquille '
            "O'Neal）代言的Papa "
            "John's。</p><p></p><p>值得一提的是，2017年時就有報導指出，詹姆斯2012年以不到100萬美元金額資助Blaze "
            'Pizza，取得大約10%的股份。短短5年之間，這家連鎖餐飲店的生意愈加茁壯，被評為全美發展速度最快的餐廳，估計市值已經達到2.5億美元。 '
            '算下來，詹姆斯的股份價值將達到至少2500萬美元。</p><p></p><div '
            'class="video-container"><iframe allowfullscreen="" '
            'class="lazyload" frameborder="0" height="315" '
            'src="https://video.udn.com/embed/news/1033151?autoplay=1&amp;muted=1" '
            'width="100%"></iframe></div>',
 'image_url': 'https://pgw.udn.com.tw/gw/photo.php?u=https://uc.udn.com.tw/photo/2019/08/09/99/6669591.jpg&x=0&y=0&sw=0&sh=0&sl=W&fw=1050&exp=3600',
 'post_datetime': '2019-08-09 10:08',
 'title': '美消費者調查報告出爐 詹皇投資比薩滿意度居首',
 'uid': '6780/3979168'}
2019-08-09 02:30:07 [scrapy.core.engine] INFO: Closing spider (finished)
2019-08-09 02:30:07 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 1283,
 'downloader/request_count': 5,
 'downloader/request_method_count/GET': 5,
 'downloader/response_bytes': 88254,
 'downloader/response_count': 5,
 'downloader/response_status_count/200': 5,
 'elapsed_time_seconds': 1.031489,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2019, 8, 9, 2, 30, 7, 573686),
 'item_scraped_count': 3,
 'log_count/DEBUG': 8,
 'log_count/INFO': 10,
 'log_count/WARNING': 5,
 'memusage/max': 74207232,
 'memusage/startup': 74207232,
 'request_depth_max': 1,
 'response_received_count': 5,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/200': 1,
 'scheduler/dequeued': 4,
 'scheduler/dequeued/memory': 4,
 'scheduler/enqueued': 4,
 'scheduler/enqueued/memory': 4,
 'start_time': datetime.datetime(2019, 8, 9, 2, 30, 6, 542197)}
2019-08-09 02:30:07 [scrapy.core.engine] INFO: Spider closed (finished)
