# -*- coding: utf-8 -*-
import scrapy

from nbaspider.nbaspider.items import NbaspiderItem


class NbaSpider(scrapy.Spider):
    name = 'nba'
    allowed_domains = ['nba.udn.com']
    url = 'https://nba.udn.com'
    index_page = '/nba/index'
    start_urls = [url + index_page]

    def parse(self, response):
        url_list = response.xpath('//div[@id="news_body"]/dl/dt/a/@href').extract()

        for story_page in url_list:
            yield scrapy.Request(self.url + story_page, callback=self.parse_detail)

    def parse_detail(self, response):
        item = NbaspiderItem()

        body_content = response.xpath('//div[@id="story_body_content"]')

        item['title'] = body_content.xpath('./h1[@class="story_art_title"]/text()').extract_first()
        item['publish_date'] = body_content.xpath('.//div[@class="shareBar__info--author"]/span/text()').extract_first()
        item['author'] = body_content.xpath('.//div[@class="shareBar__info--author"]/text()').extract_first()
        item['image_url'] = body_content.xpath('//figure/a/img/@data-src').extract_first()
        item['image_caption'] = body_content.xpath('.//figure/figcaption/text()').extract_first()
        item['video_url'] = body_content.xpath('.//div[@class="video-container"]/iframe/@src').extract_first()
        # item['content'] = ','.join(body_content.xpath('.//p').extract())

        content_list = []
        # skip the first wrong extraction
        for p in body_content.xpath('.//p')[1:]:
            s = p.xpath('string(.)').extract_first().strip()
            if s != '':
                content_list.append(s)

        # content_list = []
        # for content in contents:
        #     if 'ã€‚' in content:
        #         content = content + ','
        #     content_list.append(content)

        item['content'] = ','.join(content_list)

        # print(item['content'])

        yield item
